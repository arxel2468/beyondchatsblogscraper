```<div align="center">
  <h1>ğŸ“ BeyondChats Article Scraper & AI Improver</h1>
  <p><strong>A full-stack application that scrapes blog articles, improves them using AI, and displays both versions in a professional UI</strong></p>
  
  <p>
    <a href="#-live-demo">Live Demo</a> â€¢
    <a href="#-quick-start">Quick Start</a> â€¢
    <a href="#-architecture">Architecture</a> â€¢
    <a href="#-api-reference">API Reference</a>
  </p>

  <p>
    <img src="https://img.shields.io/badge/Node.js-18+-green?logo=node.js" alt="Node.js" />
    <img src="https://img.shields.io/badge/TypeScript-5.0-blue?logo=typescript" alt="TypeScript" />
    <img src="https://img.shields.io/badge/React-18-61dafb?logo=react" alt="React" />
    <img src="https://img.shields.io/badge/AI-Groq%20LLama%203.1-purple" alt="Groq" />
  </p>
</div>

---

## ğŸ¯ Project Overview

This project was built as a take-home assignment for **BeyondChats Full Stack Web Developer Intern** position.

### The Task (3 Phases)

| Phase | Description | Status |
|-------|-------------|--------|
| **Phase 1** | Scrape articles from BeyondChats blog, store in database, create CRUD APIs | âœ… Complete |
| **Phase 2** | Search Google for similar articles, scrape them, use LLM to improve original | âœ… Complete |
| **Phase 3** | React frontend to display original and improved articles | âœ… Complete |

---

## ğŸŒ Live Demo

- **Frontend**: [https://beyondchatsblogscraper.vercel.app](https://beyondchatsblogscraper.vercel.app) *(if deployed)*
- **Backend API**: [https://beyondchatsblogscraper-api.onrender.com](https://beyondchatsblogscraper-api.onrender.com) *(if deployed)*

---

## ğŸš€ Quick Start

### Prerequisites

- **Node.js 18+** ([Download](https://nodejs.org/))
- **Groq API Key** ([Get free key](https://console.groq.com/keys))

### 1. Clone the Repository

```bash
git clone https://github.com/arxel2468/beyondchatsblogscraper.git
cd beyondchatsblogscraper
2. Backend Setup
Bash

cd backend

# Install dependencies
npm install

# Create environment file
cp .env.example .env

# Edit .env and add your Groq API key
# GROQ_API_KEY=your_key_here

# Scrape articles from BeyondChats blog
npm run scrape

# Start the server
npm run dev
Backend will run at: http://localhost:3001

3. Frontend Setup
Bash

# Open new terminal
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
Frontend will run at: http://localhost:5173

4. Test the Application
Open http://localhost:5173 in your browser
You should see the scraped articles
Click on an article â†’ Click "Generate AI Improved Version"
Use "Compare Versions" to see original vs improved side-by-side
ğŸ—ï¸ Architecture
System Overview
text

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND                                 â”‚
â”‚                   React + TypeScript + Vite                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  HomePage   â”‚  â”‚ ArticlePage â”‚  â”‚     ComparePage         â”‚  â”‚
â”‚  â”‚  (List)     â”‚  â”‚  (Detail)   â”‚  â”‚  (Side-by-side)         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ HTTP/REST API
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         BACKEND                                  â”‚
â”‚                  Node.js + Express + TypeScript                  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      Routes Layer                         â”‚   â”‚
â”‚  â”‚         /api/articles (CRUD + Process endpoint)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Services Layer                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚  Scraper   â”‚  â”‚  Google    â”‚  â”‚  Article         â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  Service   â”‚  â”‚  Search    â”‚  â”‚  Processor       â”‚    â”‚   â”‚
â”‚  â”‚  â”‚            â”‚  â”‚  Service   â”‚  â”‚                  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚ - Cheerio  â”‚  â”‚            â”‚  â”‚ - Orchestrates   â”‚    â”‚   â”‚
â”‚  â”‚  â”‚ - Axios    â”‚  â”‚ - DuckDuck â”‚  â”‚   entire flow    â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â”‚                                           â”‚               â”‚   â”‚
â”‚  â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚                              â”‚      LLM Service       â”‚   â”‚   â”‚
â”‚  â”‚                              â”‚   (Groq - LLama 3.1)   â”‚   â”‚   â”‚
â”‚  â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Database Layer                         â”‚   â”‚
â”‚  â”‚                  SQLite + better-sqlite3                  â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚                    articles                          â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  - id, title, slug, content, excerpt                 â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  - author, published_at, source_url, image_url       â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  - is_original, original_article_id, references_json â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BeyondChats Blog   â”‚         â”‚     Groq API         â”‚
â”‚   (Source articles)  â”‚         â”‚   (LLM Processing)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Data Flow Diagram
text

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           PHASE 1: SCRAPING                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  BeyondChats Blog                Scraper Service                 Database
  (Page 15, 14...)                                                
       â”‚                               â”‚                              â”‚
       â”‚  1. Fetch page HTML           â”‚                              â”‚
       â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                              â”‚
       â”‚                               â”‚                              â”‚
       â”‚  2. Return HTML               â”‚                              â”‚
       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                              â”‚
       â”‚                               â”‚                              â”‚
       â”‚                               â”‚  3. Parse with Cheerio       â”‚
       â”‚                               â”‚  4. Extract article links    â”‚
       â”‚                               â”‚  5. Scrape each article      â”‚
       â”‚                               â”‚                              â”‚
       â”‚                               â”‚  6. Save to database         â”‚
       â”‚                               â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
       â”‚                               â”‚                              â”‚


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PHASE 2: AI PROCESSING                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   Client              Backend              DuckDuckGo        External       Groq LLM
     â”‚                    â”‚                    â”‚              Articles          â”‚
     â”‚ POST /process      â”‚                    â”‚                 â”‚              â”‚
     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                    â”‚                 â”‚              â”‚
     â”‚                    â”‚                    â”‚                 â”‚              â”‚
     â”‚                    â”‚ 1. Get original    â”‚                 â”‚              â”‚
     â”‚                    â”‚    from DB         â”‚                 â”‚              â”‚
     â”‚                    â”‚                    â”‚                 â”‚              â”‚
     â”‚                    â”‚ 2. Search query    â”‚                 â”‚              â”‚
     â”‚                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                 â”‚              â”‚
     â”‚                    â”‚                    â”‚                 â”‚              â”‚
     â”‚                    â”‚ 3. Top 2 results   â”‚                 â”‚              â”‚
     â”‚                    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                 â”‚              â”‚
     â”‚                    â”‚                    â”‚                 â”‚              â”‚
     â”‚                    â”‚ 4. Scrape articles â”‚                 â”‚              â”‚
     â”‚                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚              â”‚
     â”‚                    â”‚                    â”‚                 â”‚              â”‚
     â”‚                    â”‚ 5. Article content â”‚                 â”‚              â”‚
     â”‚                    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚              â”‚
     â”‚                    â”‚                    â”‚                 â”‚              â”‚
     â”‚                    â”‚ 6. Generate improved article         â”‚              â”‚
     â”‚                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
     â”‚                    â”‚                    â”‚                 â”‚              â”‚
     â”‚                    â”‚ 7. Improved contentâ”‚                 â”‚              â”‚
     â”‚                    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚                    â”‚                    â”‚                 â”‚              â”‚
     â”‚                    â”‚ 8. Save to DB      â”‚                 â”‚              â”‚
     â”‚                    â”‚                    â”‚                 â”‚              â”‚
     â”‚ 9. Return improved â”‚                    â”‚                 â”‚              â”‚
     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                    â”‚                 â”‚              â”‚


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       PHASE 3: FRONTEND                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    User                   React App                    Backend API
      â”‚                        â”‚                             â”‚
      â”‚  1. Open app           â”‚                             â”‚
      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                             â”‚
      â”‚                        â”‚                             â”‚
      â”‚                        â”‚  2. GET /api/articles       â”‚
      â”‚                        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
      â”‚                        â”‚                             â”‚
      â”‚                        â”‚  3. Articles list           â”‚
      â”‚                        â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
      â”‚                        â”‚                             â”‚
      â”‚  4. Display articles   â”‚                             â”‚
      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                             â”‚
      â”‚                        â”‚                             â”‚
      â”‚  5. Click article      â”‚                             â”‚
      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                             â”‚
      â”‚                        â”‚                             â”‚
      â”‚                        â”‚  6. GET /api/articles/:id   â”‚
      â”‚                        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
      â”‚                        â”‚                             â”‚
      â”‚                        â”‚  7. Article + versions      â”‚
      â”‚                        â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
      â”‚                        â”‚                             â”‚
      â”‚  8. Show detail page   â”‚                             â”‚
      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                             â”‚
ğŸ“ Project Structure
text

beyondchatsblogscraper/
â”‚
â”œâ”€â”€ backend/                          # Node.js + Express API
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.ts                  # Express app entry point
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â””â”€â”€ articles.ts           # CRUD + Process endpoints
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ scraperLight.ts       # BeyondChats blog scraper
â”‚   â”‚   â”‚   â”œâ”€â”€ googleSearch.ts       # DuckDuckGo search + external scraper
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.ts                # Groq LLM integration
â”‚   â”‚   â”‚   â””â”€â”€ articleProcessor.ts   # Orchestrates AI processing
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts              # SQLite connection
â”‚   â”‚   â”‚   â””â”€â”€ helpers.ts            # DB helper functions
â”‚   â”‚   â””â”€â”€ types/
â”‚   â”‚       â””â”€â”€ index.ts              # TypeScript interfaces
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ frontend/                         # React + Vite
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ articles.ts           # API client functions
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Header.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ArticleCard.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Loading.tsx
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ HomePage.tsx          # Article listing
â”‚   â”‚   â”‚   â”œâ”€â”€ ArticlePage.tsx       # Article detail
â”‚   â”‚   â”‚   â””â”€â”€ ComparePage.tsx       # Side-by-side comparison
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â””â”€â”€ README.md                         # This file
ğŸ“¡ API Reference
Base URL
text

http://localhost:3001/api
Endpoints
List Articles
http

GET /articles?type=original|improved&page=1&limit=10
Response:

JSON

{
  "articles": [
    {
      "id": "uuid",
      "title": "Article Title",
      "slug": "article-title-uuid",
      "content": "<p>HTML content...</p>",
      "excerpt": "Short description...",
      "author": "Author Name",
      "publishedAt": "2024-01-01T00:00:00Z",
      "sourceUrl": "https://beyondchats.com/blogs/...",
      "imageUrl": "https://...",
      "isOriginal": true,
      "originalArticleId": null,
      "references": null
    }
  ],
  "pagination": {
    "page": 1,
    "limit": 10,
    "total": 5,
    "totalPages": 1
  }
}
Get Single Article
http

GET /articles/:id
Response:

JSON

{
  "article": { ... },
  "improvedVersions": [ ... ],
  "originalArticle": null
}
Create Article
http

POST /articles
Content-Type: application/json

{
  "title": "Article Title",
  "content": "Article content...",
  "excerpt": "Optional excerpt",
  "author": "Author Name"
}
Update Article
http

PUT /articles/:id
Content-Type: application/json

{
  "title": "Updated Title",
  "content": "Updated content..."
}
Delete Article
http

DELETE /articles/:id
Process Article (AI Improvement)
http

POST /articles/:id/process
Response:

JSON

{
  "success": true,
  "message": "Article processed successfully",
  "originalId": "original-uuid",
  "improvedArticle": {
    "id": "improved-uuid",
    "title": "Improved: Article Title",
    "content": "## Improved content...",
    "isOriginal": false,
    "originalArticleId": "original-uuid",
    "references": "[{\"title\":\"Ref 1\",\"url\":\"https://...\"}]"
  }
}
ğŸ—„ï¸ Database Schema
SQL

CREATE TABLE articles (
  id TEXT PRIMARY KEY,
  title TEXT NOT NULL,
  slug TEXT UNIQUE NOT NULL,
  content TEXT NOT NULL,
  excerpt TEXT,
  author TEXT DEFAULT 'BeyondChats',
  published_at TEXT,
  source_url TEXT,
  image_url TEXT,
  is_original INTEGER DEFAULT 1,        -- 1 = original, 0 = AI improved
  original_article_id TEXT,              -- Reference to original (for improved versions)
  references_json TEXT,                  -- JSON array of reference articles
  created_at TEXT DEFAULT (datetime('now')),
  updated_at TEXT DEFAULT (datetime('now')),
  
  FOREIGN KEY (original_article_id) REFERENCES articles(id)
);
ğŸ¤– LLM Integration
Provider
Groq with LLama 3.1 8B Instant model

Why Groq?
âš¡ Extremely fast inference (~200-500ms)
ğŸ’° Generous free tier
ğŸ”„ OpenAI-compatible API
ğŸ“ˆ Easy to upgrade to larger models
Processing Flow
Original Article â†’ Extract title and clean content
Search â†’ Query DuckDuckGo for similar articles
Scrape â†’ Extract content from top 2 results
Generate â†’ Send to LLM with prompt:
System: "You are an expert content writer..."
User: Original article + Reference articles
Save â†’ Store improved version with references
Prompt Strategy
text

System Prompt:
- Expert content writer and SEO specialist
- Improve structure and readability
- Incorporate insights from references
- Keep core message intact
- Output in Markdown format

User Prompt:
- Original article title and content
- Reference articles (title, URL, content)
- Requested format: TITLE, EXCERPT, CONTENT
âš¡ Trade-offs & Decisions
Decision  Trade-off Reasoning
SQLite  Not suitable for high concurrency Simple setup, no external DB needed
DuckDuckGo  Less comprehensive than Google  More scraping-friendly, no API key needed
Cheerio Can't handle JS-rendered content  Much faster than Puppeteer, works for most blogs
LLama 3.1 8B  Less capable than 70B Faster, cheaper, good enough for this task
ğŸ”® Future Improvements
If I had more time, I would add:

 Authentication - User accounts and saved articles
 Queue System - Redis/Bull for async processing
 Better Scraping - Puppeteer fallback for JS-heavy sites
 Rate Limiting - Prevent API abuse
 Caching - Redis for API responses
 Tests - Jest unit tests, Playwright E2E
 Docker - Containerized deployment
 CI/CD - GitHub Actions pipeline
 Analytics - Track article views and processing stats
ğŸ§ª Testing
Manual Test Scenarios
Scraping Test

Bash

cd backend && npm run scrape
# Should scrape 5 oldest articles from BeyondChats
API Test

Bash

# List articles
curl http://localhost:3001/api/articles

# Get single article
curl http://localhost:3001/api/articles/{id}

# Process article
curl -X POST http://localhost:3001/api/articles/{id}/process
Frontend Test

Open http://localhost:5173
Verify articles load
Click "Generate AI Improved Version"
Use "Compare Versions"
ğŸ“„ Environment Variables
Backend (backend/.env)
env

# Server
PORT=3001

# Database
DATABASE_PATH=./data/articles.db

# Groq API (Required for AI processing)
GROQ_API_KEY=gsk_your_api_key_here
Frontend (frontend/.env)
env

# API URL (optional, defaults to /api with proxy)
VITE_API_URL=http://localhost:3001/api
ğŸ”’ Security Notes
âœ… API keys stored in .env (not committed)
âœ… Input validation with Zod schemas
âœ… SQL injection prevented via parameterized queries
âœ… CORS configured for frontend origin
âœ… Request body size limited

ğŸ‘¤ Author
Amit Pandit (@arxel2468)

ğŸ“œ License
This project was created as a take-home assignment. The code is my own work and is shared for evaluation purposes.

<div align="center"> <sub>Built with â¤ï¸ for BeyondChats</sub> </div> ```
